{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part3_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuhycWGLYab6",
        "colab_type": "code",
        "outputId": "90712d6d-2744-4f78-dd9d-561f17296246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "import os\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.4\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.4.5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_252\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
            "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n",
            "Processing /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471/pyspark-2.4.4-py2.py3-none-any.whl\n",
            "Collecting py4j==0.10.7\n",
            "  Using cached https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "py4j",
                  "pyspark"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting spark-nlp==2.4.5\n",
            "  Using cached https://files.pythonhosted.org/packages/31/46/5c5a2bda407f693126386da5378f132e5e163fa6dfa46109548270348786/spark_nlp-2.4.5-py2.py3-none-any.whl\n",
            "Installing collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.4.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "com",
                  "sparknlp"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te1HoinhY9DF",
        "colab_type": "code",
        "outputId": "6e1cac25-34a5-4f6e-d067-55836dbf123e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import findspark\n",
        "findspark.init('/home/cse587/spark-2.4.0-bin-hadoop2.7')\n",
        "\n",
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version\")\n",
        "sparknlp.version()\n",
        "print(\"Apache Spark version\")\n",
        "spark.version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version\n",
            "Apache Spark version\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.4.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYUAVdTEdq9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark import SQLContext\n",
        "\n",
        "sc = SparkContext.getOrCreate()\n",
        "sqlContext = SQLContext(sc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8hdqD7zd425",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.types import IntegerType,ArrayType, StringType\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.functions import col\n",
        "from copy import deepcopy\n",
        "\n",
        "import ast"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBZkbSUIo2K3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "data = sqlContext.read.csv('train.csv',header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLA79NBypKH5",
        "colab_type": "code",
        "outputId": "a6143e1c-4dc1-43fa-8e99-94b6f2f3599d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "document = DocumentAssembler().setInputCol('plot').setOutputCol('document').setCleanupMode('shrink')\n",
        "tokenizer = Tokenizer().setInputCols(['document']).setOutputCol('tokens')\n",
        "stopWords = StopWordsCleaner().setInputCols('tokens').setOutputCol('clean')\n",
        "lemma = LemmatizerModel().pretrained('lemma_antbnc').setInputCols(['clean']).setOutputCol('lemma')\n",
        "embeddings = WordEmbeddingsModel.pretrained().setInputCols(['document','lemma']).setOutputCol('embeddings')\n",
        "sentence = SentenceEmbeddings().setInputCols(['document','embeddings']).setOutputCol('sentence_embeddings').setPoolingStrategy('AVERAGE')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n",
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RYpBoBR1U5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf_pipeline = Pipeline (\n",
        "    stages = [\n",
        "              document,\n",
        "              tokenizer,\n",
        "              stopWords,\n",
        "              lemma,\n",
        "              embeddings,\n",
        "              sentence\n",
        "    ])\n",
        "\n",
        "model = clf_pipeline.fit(data)\n",
        "dataset = model.transform(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcDZxyrXfsKS",
        "colab_type": "code",
        "outputId": "df5b0867-5d85-40fe-d257-99bdb534bfbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[movie_id: string, features: vector, genre: string, label: array<bigint>, Drama: bigint, Comedy: bigint, Romance Film: bigint, Thriller: bigint, Action: bigint, World cinema: bigint, Crime Fiction: bigint, Horror: bigint, Black-and-white: bigint, Indie: bigint, Action/Adventure: bigint, Adventure: bigint, Family Film: bigint, Short Film: bigint, Romantic drama: bigint, Animation: bigint, Musical: bigint, Science Fiction: bigint, Mystery: bigint, Romantic comedy: bigint]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHJ46U3IdkZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.linalg import Vectors,DenseVector, VectorUDT\n",
        "from pyspark.sql.functions import col,udf\n",
        "\n",
        "to_vector_udf = udf(lambda vs: Vectors.dense(vs), VectorUDT())\n",
        "dataset = dataset.withColumn('features',to_vector_udf(col('sentence_embeddings')[0].embeddings))\n",
        "\n",
        "dataset = dataset.select('movie_id','features','genre')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5Acm98V0a5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "d = pd.read_csv('mapping.csv',index_col=0)\n",
        "df = d.to_dict()['0']\n",
        "\n",
        "dic = dict((v,k) for k,v in df.items())\n",
        "encode = [0] * len(dic.keys())\n",
        "\n",
        "\n",
        "from ast import literal_eval\n",
        "from copy import deepcopy\n",
        "\n",
        "def kHotEncode(x):\n",
        "    global dic\n",
        "    global encode\n",
        "\n",
        "    key = deepcopy(encode)\n",
        "    try:\n",
        "        labs = list(literal_eval(x))\n",
        "        res = []\n",
        "        for lab in labs:\n",
        "            if lab in dic.keys(): key[dic[lab]] = 1\n",
        "        return key\n",
        "    except:\n",
        "        return [0] * 20\n",
        "\n",
        "udf_encode = udf(kHotEncode, ArrayType(IntegerType()))\n",
        "\n",
        "dataset = dataset.withColumn(\"label\", udf_encode(col(\"genre\")))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROPccyhG07Rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = dataset.columns\n",
        "labels = list(dic.keys())\n",
        "\n",
        "dataset = dataset.rdd.map(lambda row: ([row[c] for c in cols]+row['label'])).toDF(cols+labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwtVjNhyqSEF",
        "colab_type": "code",
        "outputId": "c2b0780b-11de-4ec8-e5e4-471e584c914f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        }
      },
      "source": [
        "dataset.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+--------------------+--------------------+-----+------+------------+--------+------+------------+-------------+------+---------------+-----+----------------+---------+-----------+----------+--------------+---------+-------+---------------+-------+---------------+\n",
            "|movie_id|            features|               genre|               label|Drama|Comedy|Romance Film|Thriller|Action|World cinema|Crime Fiction|Horror|Black-and-white|Indie|Action/Adventure|Adventure|Family Film|Short Film|Romantic drama|Animation|Musical|Science Fiction|Mystery|Romantic comedy|\n",
            "+--------+--------------------+--------------------+--------------------+-----+------+------------+--------+------+------------+-------------+------+---------------+-----+----------------+---------+-----------+----------+--------------+---------+-------+---------------+-------+---------------+\n",
            "|23890098|[0.04802859947085...|['World cinema', ...|[1, 0, 0, 0, 0, 1...|    1|     0|           0|       0|     0|           1|            0|     0|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
            "|31186339|[-0.0127709610387...| Peeta unexpected...|[0, 0, 0, 0, 0, 0...|    0|     0|           0|       0|     0|           0|            0|     0|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
            "|20663735|[-0.0175490379333...|['Musical', 'Acti...|[1, 0, 0, 0, 1, 0...|    1|     0|           0|       0|     1|           0|            0|     0|              0|    0|               0|        0|          0|         0|             0|        0|      1|              0|      0|              0|\n",
            "| 2231378|[0.13781112432479...| as does the mone...|[0, 0, 0, 0, 0, 0...|    0|     0|           0|       0|     0|           0|            0|     0|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
            "|  595909|[-0.0101427081972...| the public is qu...|[0, 0, 0, 0, 0, 0...|    0|     0|           0|       0|     0|           0|            0|     0|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
            "| 5272176|[-0.1114593446254...|['Action/Adventur...|[1, 0, 0, 1, 1, 0...|    1|     0|           0|       1|     1|           0|            0|     0|              0|    0|               1|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
            "| 1952976|[0.03566912189126...| which is just a ...|[0, 0, 0, 0, 0, 0...|    0|     0|           0|       0|     0|           0|            0|     0|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
            "|24225279|[-0.0468842759728...|           ['Drama']|[1, 0, 0, 0, 0, 0...|    1|     0|           0|       0|     0|           0|            0|     0|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
            "| 2462689|[-0.1183273792266...| the newspaper ed...|[0, 0, 0, 0, 0, 0...|    0|     0|           0|       0|     0|           0|            0|     0|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
            "|20532852|[-0.0264587309211...| he sneaks in and...|[0, 0, 0, 0, 0, 0...|    0|     0|           0|       0|     0|           0|            0|     0|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
            "|15401493|[-0.0094703538343...|          ['Comedy']|[0, 1, 0, 0, 0, 0...|    0|     1|           0|       0|     0|           0|            0|     0|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
            "|18188932|[0.03231011703610...|['Crime Fiction',...|[1, 1, 0, 0, 0, 1...|    1|     1|           0|       0|     0|           1|            1|     0|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
            "| 2940516|[-0.0923868715763...|          ['Comedy']|[0, 1, 0, 0, 0, 0...|    0|     1|           0|       0|     0|           0|            0|     0|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
            "| 1480747|[0.01358244940638...| causing a rift b...|[0, 0, 0, 0, 0, 0...|    0|     0|           0|       0|     0|           0|            0|     0|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
            "|24448645|[-0.0512655936181...|          ['Horror']|[0, 0, 0, 0, 0, 0...|    0|     0|           0|       0|     0|           0|            0|     1|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
            "|15072401|[-0.0203181710094...|['Crime Fiction',...|[0, 0, 0, 1, 0, 0...|    0|     0|           0|       1|     0|           0|            1|     1|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      1|              0|\n",
            "| 4018288|[-0.0621435716748...|\"\" who thinks she...|[0, 0, 0, 0, 0, 0...|    0|     0|           0|       0|     0|           0|            0|     0|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
            "| 4596602|[0.04921400547027...|['Crime Fiction',...|[0, 0, 1, 1, 1, 0...|    0|     0|           1|       1|     1|           0|            1|     0|              0|    1|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
            "|15224586|[-0.0790124535560...|  ['Indie', 'Drama']|[1, 0, 0, 0, 0, 0...|    1|     0|           0|       0|     0|           0|            0|     0|              0|    1|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
            "|15585766|[-0.1853742748498...|           ['Drama']|[1, 0, 0, 0, 0, 0...|    1|     0|           0|       0|     0|           0|            0|     0|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
            "+--------+--------------------+--------------------+--------------------+-----+------+------------+--------+------+------------+-------------+------+---------------+-----+----------------+---------+-----------+----------+--------------+---------+-------+---------------+-------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RLeyASJJkWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\n",
        "\n",
        "load_model = []\n",
        "try:\n",
        "  for i in range(20):\n",
        "    path = \"lr_ml_model/\"+str(i)+\"/\"\n",
        "    load_model.append(LogisticRegressionModel.load(path))\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKKbVV6u32MC",
        "colab_type": "code",
        "outputId": "9aa0b2f1-9e67-406f-e1be-cf3a2237e60b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
        "import time\n",
        "\n",
        "\n",
        "label_names = list(dic.keys())\n",
        "lr_models = []\n",
        "\n",
        "if (len(load_model) != 20):\n",
        "  start = time.time()\n",
        "  for index,label_name in enumerate(label_names):\n",
        "    print(label_name, time.time()-start)\n",
        "    lr = LogisticRegression(maxIter=10, predictionCol='lr_prediction', labelCol=label_name, regParam=0.3, elasticNetParam=0)\n",
        "    lr_models.append(lr.fit(dataset))\n",
        "  print(time.time()-start)\n",
        "else:\n",
        "  lr_models = load_model\n",
        "\n",
        "load_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[LogisticRegressionModel: uid = LogisticRegression_21115049c225, numClasses = 2, numFeatures = 100,\n",
              " LogisticRegressionModel: uid = LogisticRegression_837cd0f16974, numClasses = 2, numFeatures = 100,\n",
              " LogisticRegressionModel: uid = LogisticRegression_ba94f5b88122, numClasses = 2, numFeatures = 100,\n",
              " LogisticRegressionModel: uid = LogisticRegression_3f26494d31a8, numClasses = 2, numFeatures = 100,\n",
              " LogisticRegressionModel: uid = LogisticRegression_5afca6cf1c1c, numClasses = 2, numFeatures = 100,\n",
              " LogisticRegressionModel: uid = LogisticRegression_73a43171c212, numClasses = 2, numFeatures = 100,\n",
              " LogisticRegressionModel: uid = LogisticRegression_e83efcdd7d2f, numClasses = 2, numFeatures = 100,\n",
              " LogisticRegressionModel: uid = LogisticRegression_3552e959aede, numClasses = 2, numFeatures = 100,\n",
              " LogisticRegressionModel: uid = LogisticRegression_642d39e0b20b, numClasses = 2, numFeatures = 100,\n",
              " LogisticRegressionModel: uid = LogisticRegression_1d7838628a3e, numClasses = 2, numFeatures = 100,\n",
              " LogisticRegressionModel: uid = LogisticRegression_db89cdf9ae73, numClasses = 2, numFeatures = 100,\n",
              " LogisticRegressionModel: uid = LogisticRegression_c70c97e28cc1, numClasses = 2, numFeatures = 100,\n",
              " LogisticRegressionModel: uid = LogisticRegression_5513b50ae8e5, numClasses = 2, numFeatures = 100,\n",
              " LogisticRegressionModel: uid = LogisticRegression_cbfae3eefef3, numClasses = 2, numFeatures = 100,\n",
              " LogisticRegressionModel: uid = LogisticRegression_ffc47be95f38, numClasses = 2, numFeatures = 100,\n",
              " LogisticRegressionModel: uid = LogisticRegression_b9a12b6fb8c3, numClasses = 2, numFeatures = 100,\n",
              " LogisticRegressionModel: uid = LogisticRegression_40c5c2b39ae0, numClasses = 2, numFeatures = 100,\n",
              " LogisticRegressionModel: uid = LogisticRegression_1a46917c2b70, numClasses = 2, numFeatures = 100,\n",
              " LogisticRegressionModel: uid = LogisticRegression_718a819de884, numClasses = 2, numFeatures = 100,\n",
              " LogisticRegressionModel: uid = LogisticRegression_fce6446e524f, numClasses = 2, numFeatures = 100]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGULLLXY6aqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for index,model in enumerate(lr_models):\n",
        "#   model.save('lr_ml_model/'+str(index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWee_OG4g6qU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing = sqlContext.read.csv('test.csv',header=True)\n",
        "\n",
        "test_pipeline = Pipeline (\n",
        "    stages = [\n",
        "              document,\n",
        "              tokenizer,\n",
        "              stopWords,\n",
        "              lemma,\n",
        "              embeddings,\n",
        "              sentence,\n",
        "    ])\n",
        "\n",
        "test_model = test_pipeline.fit(testing)\n",
        "test_dataset = test_model.transform(testing)\n",
        "test_dataset = test_dataset.withColumn('features',to_vector_udf(col('embeddings')[0].embeddings))\n",
        "test_dataset = test_dataset.select('movie_id','features')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVxeObzZIiaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = []\n",
        "start = time.time()\n",
        "for i in range(len(lr_models)):\n",
        "  print(i, time.time()-start, end=' ')\n",
        "  start = time.time()\n",
        "  pred = lr_models[i].transform(test_dataset)\n",
        "  preds.append(pred.select('movie_id','lr_prediction').toPandas())\n",
        "  print(time.time()-start)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwCVxeC_6QU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_cpy = [p.copy() for p in preds]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbs0FJFFgY6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_cpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGFyS0Ia43HY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = preds_cpy[0].copy()\n",
        "df.columns = ['movie_id', '0']\n",
        "df['0'] = df['0'].astype(int).astype(str).copy()\n",
        "df\n",
        "for i in range(1,20):\n",
        "  tmp = preds_cpy[i].copy()\n",
        "  tmp.columns = ['movie_id',str(i)]\n",
        "  tmp[str(i)] = tmp[str(i)].astype(int).astype(str)\n",
        "  df = df.merge(tmp, on='movie_id', how='left')\n",
        "\n",
        "\n",
        "df['prediction'] = df[[str(i) for i in range(20)]].apply(lambda x: ' '.join(x), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywt2zH1u7d_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_new = df[['movie_id', 'prediction']]\n",
        "df_new.to_csv('result_part3.csv',header=True,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}